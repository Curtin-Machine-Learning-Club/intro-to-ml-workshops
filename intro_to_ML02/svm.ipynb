{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification: Support Vector Machines\n",
    "\n",
    "Enough with the simple stuff! Now let's use SVMs.\n",
    "\n",
    "SVMs maximise the margin between the support vectors.\n",
    "\n",
    "References:\n",
    "Plot Iris SVC: https://scikit-learn.org/stable/auto_examples/svm/plot_iris_svc.html <br>\n",
    "Recognizing hand-written digits: https://scikit-learn.org/stable/auto_examples/classification/plot_digits_classification.html#sphx-glr-auto-examples-classification-plot-digits-classification-py <br>\n",
    "Confusion matrix: https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy\n",
    "%pip install matplotlib\n",
    "%pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, datasets, metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying the Iris dataset\n",
    "\n",
    "We've used Iris a lot now, but we haven't seen SVMs do it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing the Iris dataset\n",
    "\n",
    "Let's view the dataset one more time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_x, iris_y = datasets.load_iris(return_X_y=True, as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing our inputs\n",
    "\n",
    "Once again, let's use the sepal length and width as our inputs, with a train/test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out the petal width and length, then convert to a numpy array\n",
    "\n",
    "# Split the data into training and testing sets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click to cheat</summary>\n",
    "\n",
    "```python\n",
    "# Filter out the petal width and length, then convert to a numpy array\n",
    "iris_sepal = iris_x.filter(items=['sepal length (cm)', 'sepal width (cm)']).to_numpy()\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    iris_sepal, iris_y.to_numpy(), train_size=0.7\n",
    ")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating our models using different kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose your hyper parameters\n",
    "# C = \n",
    "# gamma = \n",
    "# degree = \n",
    "\n",
    "# Create the models\n",
    "models = (\n",
    "    # Create a SVC with a linear kernel\n",
    "\n",
    "    # Create a LinearSVC with a max_iter of a big number\n",
    "\n",
    "    # Create a SVC with a RBF kernel\n",
    "\n",
    "    # Create a SVC with a polynomial kernel\n",
    "\n",
    ")\n",
    "\n",
    "# Train the models and store in a list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click to cheat</summary>\n",
    "\n",
    "```python\n",
    "# Choose your hyper parameters\n",
    "C = 1.0\n",
    "gamma = 0.5\n",
    "degree = 3\n",
    "\n",
    "# Create the models\n",
    "models = (\n",
    "    # Create a SVC with a linear kernel\n",
    "    svm.SVC(kernel='linear', C=C),\n",
    "    # Create a LinearSVC with a max_iter of a big number\n",
    "    svm.LinearSVC(C=C, max_iter=10000),\n",
    "    # Create a SVC with a RBF kernel\n",
    "    svm.SVC(kernel='rbf', gamma=gamma, C=C),\n",
    "    # Create a SVC with a polynomial kernel\n",
    "    svm.SVC(kernel=\"poly\", degree=degree, gamma=\"auto\", C=C)\n",
    ")\n",
    "\n",
    "# Train the models and store in a list\n",
    "models2 = [model.fit(X_train, y_train) for model in models]\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the Hyperplanes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_meshgrid(x, y, h=0.02):\n",
    "    x_min, x_max = x.min() - 1, x.max() + 1\n",
    "    y_min, y_max = y.min() - 1, y.max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    return xx, yy\n",
    "\n",
    "\n",
    "def plot_contours(ax, clf, xx, yy, **params):\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    out = ax.contourf(xx, yy, Z, **params)\n",
    "    return out\n",
    "\n",
    "titles = (\n",
    "    f\"SVC with linear kernel (C = {C})\",\n",
    "    \"LinearSVC (linear kernel)\",\n",
    "    f\"SVC with RBF kernel (gamma = {gamma})\",\n",
    "    f\"SVC with polynomial (degree {degree}) kernel\",\n",
    ")\n",
    "\n",
    "# Set-up 2x2 grid for plotting.\n",
    "fig, sub = plt.subplots(2, 2)\n",
    "plt.subplots_adjust(wspace=0.4, hspace=0.4)\n",
    "\n",
    "train_x0, train_x1 = X_train[:, 0], X_train[:, 1]\n",
    "test_x0, test_x1 = X_test[:, 0], X_test[:, 1]\n",
    "xx, yy = make_meshgrid(iris_sepal[:,0], iris_sepal[:,1])\n",
    "\n",
    "for model, title, ax in zip(models2, titles, sub.flatten()):\n",
    "    plot_contours(ax, model, xx, yy, cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "    ax.scatter(train_x0, train_x1, c=y_train, cmap=plt.cm.coolwarm, s=20, edgecolors=\"k\")\n",
    "    ax.scatter(test_x0, test_x1, c=y_test, cmap=plt.cm.coolwarm, s=40, edgecolors=\"k\", marker='*')\n",
    "    ax.set_xlim(xx.min(), xx.max())\n",
    "    ax.set_ylim(yy.min(), yy.max())\n",
    "    ax.set_xlabel(\"Sepal length\")\n",
    "    ax.set_ylabel(\"Sepal width\")\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    ax.set_title(title)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix of our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "titles_options = [\n",
    "    (\"Confusion matrix, without normalization\", None),\n",
    "    (\"Normalized confusion matrix\", \"true\"),\n",
    "]\n",
    "\n",
    "# pick a model from our trained models\n",
    "model = models2[0]\n",
    "\n",
    "for title, normalize in titles_options:\n",
    "    disp = ConfusionMatrixDisplay.from_estimator(\n",
    "        model,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        display_labels=iris.target_names,\n",
    "        cmap=plt.cm.Blues,\n",
    "        normalize=normalize,\n",
    "    )\n",
    "    disp.ax_.set_title(title)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digits dataset\n",
    "\n",
    "Enough of Iris! Let's start using the digits dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data\n",
    "\n",
    "First things first, we need to load the data. Let's also view the first few samples while we're at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the digits as a bunch object\n",
    "# We do this to get the target names and images for plotting\n",
    "\n",
    "# Also load the digits X as a pandas Dataframe and the y as a Series\n",
    "\n",
    "\n",
    "# Plot the first few examples\n",
    "_, axes = plt.subplots(nrows=1, ncols=4, figsize=(10, 3))\n",
    "for ax, image, label in zip(axes, digits.images, digits.target):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "    ax.set_title(f\"Digit {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click to cheat</summary>\n",
    "\n",
    "```python\n",
    "# Load the digits as a bunch object\n",
    "# We do this to get the target names and images for plotting\n",
    "digits = datasets.load_digits()\n",
    "# Also load the digits X as a pandas Dataframe and the y as a Series\n",
    "digits_X, digits_y = datasets.load_digits(return_X_y=True, as_frame=True)\n",
    "\n",
    "# Plot the first few examples\n",
    "_, axes = plt.subplots(nrows=1, ncols=4, figsize=(10, 3))\n",
    "for ax, image, label in zip(axes, digits.images, digits.target):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "    ax.set_title(f\"Digit {label}\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's split our labelled data into training and testing sets with a 70/30 ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click to cheat</summary>\n",
    "\n",
    "```python\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    digits_X.to_numpy(), digits_y.to_numpy(), test_size=0.7\n",
    ")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the untrained model\n",
    "# Choose whatever kernel you want\n",
    "\n",
    "\n",
    "# Train the model\n",
    "\n",
    "\n",
    "# get the predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click to cheat</summary>\n",
    "\n",
    "```python\n",
    "# Create the untrained model\n",
    "# Choose whatever kernel you want\n",
    "model = svm.SVC(kernel='rbf', gamma=0.001, C=1.0)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# get the predictions\n",
    "y_pred = model.predict(X_test)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model\n",
    "\n",
    "Let's see a few examples of our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(nrows=1, ncols=4, figsize=(10, 3))\n",
    "for ax, image, prediction in zip(axes, X_test, y_pred):\n",
    "    ax.set_axis_off()\n",
    "    image = image.reshape(8, 8)\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "    ax.set_title(f\"Prediction: {prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also view our confusion matrix for good measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = metrics.ConfusionMatrixDisplay.from_predictions(y_test, y_pred)\n",
    "disp.figure_.suptitle(\"Confusion Matrix\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll look at our measures of performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "target_names = [str(name) for name in digits.target_names]\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3e8ba394dfecf69ab3b214a23e7e279956d3407d86cf3cc4fe5cfb6d1f0e6e68"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
