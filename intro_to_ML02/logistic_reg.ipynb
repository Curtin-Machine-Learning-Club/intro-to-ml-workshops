{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification: Logistic Regression\n",
    "\n",
    "Despite the name, logistic regression is actually a classification algorithm.\n",
    "\n",
    "Using simple probabilities, logistic regression uses an output variable from 0-1 to determine the probability of the given input belonging to a certain class or not. When comparing this probability to a threshold (usually 0.5), we can determine if the probability is high enough to say that it indeed belongs to that class.\n",
    "\n",
    "References:\n",
    "Logistic Regression 3-class Classifier: https://scikit-learn.org/stable/auto_examples/linear_model/plot_iris_logistic.html <br>\n",
    "Confusion matrix: https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy\n",
    "%pip install matplotlib\n",
    "%pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import datasets, metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying the Iris dataset\n",
    "\n",
    "Since we're familiar with it already, let's continue using the Iris dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing the Iris dataset\n",
    "\n",
    "Let's view the dataset one more time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_x, iris_y = datasets.load_iris(return_X_y=True, as_frame=True)\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing our inputs\n",
    "\n",
    "Once again, let's use the sepal length and width as our inputs, with a train/test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out the petal width and length, then convert to a numpy array\n",
    "\n",
    "# Split the data into training and testing sets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click to cheat</summary>\n",
    "\n",
    "```python\n",
    "# Filter out the petal width and length, then convert to a numpy array\n",
    "iris_sepal = iris_x.filter(items=['sepal length (cm)', 'sepal width (cm)']).to_numpy()\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    iris_sepal, iris_y.to_numpy(), train_size=0.7\n",
    ")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating our logistic regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose your C value. Smaller values result in stronger regularization\n",
    "# C = \n",
    "\n",
    "# Create the models\n",
    "models = [\n",
    "    # Create one with OVR multi-class handling\n",
    "    \n",
    "    # Create another with multinomial class handling\n",
    "    \n",
    "]\n",
    "\n",
    "# Train the models and store in a list called models2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click to cheat</summary>\n",
    "\n",
    "```python\n",
    "# Choose your C value. Smaller values result in stronger regularization\n",
    "C = 0.1\n",
    "\n",
    "# Create the models\n",
    "models = [\n",
    "    # Create one with OVR multi-class handling\n",
    "    LogisticRegression(C=C, multi_class='ovr'),\n",
    "    # Create another with multinomial class handling\n",
    "    LogisticRegression(C=C, multi_class='multinomial')\n",
    "]\n",
    "\n",
    "# Train the models and store in a list called models2\n",
    "models2 = [model.fit(X_train, y_train) for model in models]\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = (\n",
    "    \"Logistic regression using OVR\",\n",
    "    \"Logistic regression using multinomial\"\n",
    ")\n",
    "\n",
    "# Set-up len(models)x1 grid for plotting.\n",
    "fig, sub = plt.subplots(nrows=1, ncols=len(models2), figsize=(5 * len(models2), 5),\n",
    "        constrained_layout=True)\n",
    "h = 0.05    # step size for mesh grid\n",
    "\n",
    "cmap_light = ListedColormap([\"#FFAAAA\", \"#AAFFAA\", \"#AAAAFF\"])\n",
    "cmap_bold = ListedColormap([\"#FF0000\", \"#00FF00\", \"#0000FF\"])\n",
    "\n",
    "x_min, x_max = iris_sepal[:, 0].min() - 0.3, iris_sepal[:, 0].max() + 0.3\n",
    "y_min, y_max = iris_sepal[:, 1].min() - 0.3, iris_sepal[:, 1].max() + 0.3\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "for title, model, ax in zip(titles, models2, sub.flatten()):\n",
    "    # Get the accuracy as a number from 0-1\n",
    "    score = model.score(X_test, y_test)\n",
    "\n",
    "    # Plot the decision boundary. For that, we will assign a color to each\n",
    "    # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    ax.pcolormesh(xx, yy, Z, cmap=cmap_light, alpha=0.8)\n",
    "\n",
    "    # Plot also the training and testing points\n",
    "    ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cmap_bold, edgecolor=\"k\", s=20)\n",
    "    ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cmap_bold, edgecolor=\"k\", s=40, marker='*')\n",
    "    ax.set_xlim(xx.min(), xx.max())\n",
    "    ax.set_ylim(yy.min(), yy.max())\n",
    "    ax.title.set_text(f\"{title}\")\n",
    "    ax.text(\n",
    "        0.9, 0.1,\n",
    "        f\"{score:.2f}\",\n",
    "        size=15,\n",
    "        ha=\"center\",\n",
    "        va=\"center\",\n",
    "        transform=ax.transAxes,\n",
    "    )\n",
    "\n",
    "fig.supylabel(\"sepal length (cm)\")\n",
    "fig.supxlabel(\"sepal width (cm)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix of our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "titles_options = [\n",
    "    (\"Confusion matrix, without normalization\", None),\n",
    "    (\"Normalized confusion matrix\", \"true\"),\n",
    "]\n",
    "\n",
    "# pick a model from our trained models\n",
    "# model = models2[0]\n",
    "\n",
    "for title, normalize in titles_options:\n",
    "    disp = ConfusionMatrixDisplay.from_estimator(\n",
    "        model,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        display_labels=iris.target_names,\n",
    "        cmap=plt.cm.Blues,\n",
    "        normalize=normalize,\n",
    "    )\n",
    "    disp.ax_.set_title(title)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digits dataset\n",
    "\n",
    "Similarly, we can try logistic regression on the digits dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data\n",
    "\n",
    "First things first, we need to load the data. Let's also view the first few samples while we're at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the digits as a bunch object\n",
    "# We do this to get the target names and images for plotting\n",
    "\n",
    "# Also load the digits X as a pandas Dataframe and the y as a Series\n",
    "\n",
    "\n",
    "\n",
    "# Plot the first few examples\n",
    "_, axes = plt.subplots(nrows=1, ncols=4, figsize=(10, 3))\n",
    "for ax, image, label in zip(axes, digits.images, digits.target):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "    ax.set_title(f\"Digit {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click to cheat</summary>\n",
    "\n",
    "```python\n",
    "# Load the digits as a bunch object\n",
    "# We do this to get the target names and images for plotting\n",
    "digits = datasets.load_digits()\n",
    "# Also load the digits X as a pandas Dataframe and the y as a Series\n",
    "digits_X, digits_y = datasets.load_digits(return_X_y=True, as_frame=True)\n",
    "\n",
    "# Plot the first few examples\n",
    "_, axes = plt.subplots(nrows=1, ncols=4, figsize=(10, 3))\n",
    "for ax, image, label in zip(axes, digits.images, digits.target):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "    ax.set_title(f\"Digit {label}\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's split our labelled data into training and testing sets with a 70/30 ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click to cheat</summary>\n",
    "\n",
    "```python\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    digits_X.to_numpy(), digits_y.to_numpy(), train_size=0.7\n",
    ")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the untrained model\n",
    "# Choose C and multi-class handling you want\n",
    "\n",
    "\n",
    "# Train the model\n",
    "\n",
    "\n",
    "# get the predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click to cheat</summary>\n",
    "\n",
    "```python\n",
    "# Create the untrained model\n",
    "# Choose C and multi-class handling you want\n",
    "model = LogisticRegression(C=1.0, multi_class='ovr')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# get the predictions\n",
    "y_pred = model.predict(X_test)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model\n",
    "\n",
    "Let's see a few examples of our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(nrows=1, ncols=4, figsize=(10, 3))\n",
    "for ax, image, prediction in zip(axes, X_test, y_pred):\n",
    "    ax.set_axis_off()\n",
    "    image = image.reshape(8, 8)\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "    ax.set_title(f\"Prediction: {prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also view our confusion matrix for good measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = metrics.ConfusionMatrixDisplay.from_predictions(y_test, y_pred)\n",
    "disp.figure_.suptitle(\"Confusion Matrix\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll look at our measures of performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "target_names = [str(name) for name in digits.target_names]\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3e8ba394dfecf69ab3b214a23e7e279956d3407d86cf3cc4fe5cfb6d1f0e6e68"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
