{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Detection\n",
    "\n",
    "More often then ever, we need the ability to scan through data and find anomilies or novelties.\n",
    "\n",
    "Scikit learn provides several novelty detection algorithms. We'll focus on Local Outlier Factor (LOF) and Isolation Forest.\n",
    "\n",
    "References:<br>\n",
    "Novelty detection with Local Outlier Factor: https://scikit-learn.org/stable/auto_examples/neighbors/plot_lof_novelty_detection.html <br>\n",
    "IsolationForest example: https://scikit-learn.org/stable/auto_examples/ensemble/plot_isolation_forest.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy\n",
    "%pip install matplotlib\n",
    "%pip install sklearn\n",
    "%pip install seaborn\n",
    "%pip install -U matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Novelty Detection with LOF\n",
    "\n",
    "After providing sample data, LOF can determine if new samples are different enough to be considered novel.\n",
    "\n",
    "LOF uses KNN to detect the neighbors for each point, then determines if it's novel based on the density of the point relative to the densities of the neighbors. If the point's density to too low relative to the neighbors' densities, then it is considered novel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the data\n",
    "\n",
    "Let's create the data and see what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training and testing data\n",
    "# Note that the sets are not labelled, so this is not supervised!\n",
    "\n",
    "\n",
    "# generate abnormal data\n",
    "\n",
    "\n",
    "# plot the data\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], color='b', label=\"train\")\n",
    "plt.scatter(X_test[:, 0], X_test[:, 1], color='g', label=\"test\")\n",
    "plt.scatter(X_outliers[:, 0], X_outliers[:, 1], color='m', label=\"outliers\")\n",
    "plt.xlabel(\"$x_1$\")\n",
    "plt.ylabel(\"$x_2$\")\n",
    "plt.title(\"Ground truth clusters\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click to cheat</summary>\n",
    "\n",
    "```python\n",
    "# Generate training and testing data\n",
    "# Note that the sets are not labelled, so this is not supervised!\n",
    "X = 0.3 * np.random.randn(50, 2)\n",
    "X_train = np.r_[X + 2, X - 2]\n",
    "X = 0.3 * np.random.randn(50, 2)\n",
    "X_test = np.r_[X + 2, X - 2]\n",
    "\n",
    "# generate abnormal data\n",
    "X_outliers = np.random.uniform(low=-4, high=4, size=(20, 2))\n",
    "\n",
    "# plot the data\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], color='b', label=\"train\")\n",
    "plt.scatter(X_test[:, 0], X_test[:, 1], color='g', label=\"test\")\n",
    "plt.scatter(X_outliers[:, 0], X_outliers[:, 1], color='m', label=\"outliers\")\n",
    "plt.xlabel(\"$x_1$\")\n",
    "plt.ylabel(\"$x_2$\")\n",
    "plt.title(\"Ground truth clusters\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating our Novelty Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "# Create the LOF detector with k=20, novelty=True, and contamination=0.1\n",
    "\n",
    "\n",
    "# train the LOF\n",
    "\n",
    "\n",
    "# get the predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click to cheat</summary>\n",
    "\n",
    "```python\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "# Create the LOF detector with k=20, novelty=True, and contamination=0.1\n",
    "lof = LocalOutlierFactor(n_neighbors=20, novelty=True, contamination=0.1)\n",
    "\n",
    "# train the LOF\n",
    "lof.fit(X_train)\n",
    "\n",
    "# get the predictions\n",
    "y_pred_test = lof.predict(X_test)\n",
    "y_pred_outliers = lof.predict(X_outliers)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the number of Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of test errors\n",
    "\n",
    "\n",
    "# Get the number of outlier errors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click to cheat</summary>\n",
    "\n",
    "```python\n",
    "# Get the number of test errors\n",
    "n_errors_test = y_pred_test[y_pred_test == -1].size\n",
    "\n",
    "# Get the number of outlier errors\n",
    "n_errors_outliers = y_pred_outliers[y_pred_outliers == 1].size\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx, yy = np.meshgrid(np.linspace(-5, 5, 500), np.linspace(-5, 5, 500))\n",
    "\n",
    "# plot the learned frontier, the points, and the nearest vectors to the plane\n",
    "Z = lof.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "plt.title(\"Novelty Detection with LOF\")\n",
    "plt.contourf(xx, yy, Z, levels=np.linspace(Z.min(), 0, 7), cmap=plt.cm.PuBu)\n",
    "a = plt.contour(xx, yy, Z, levels=[0], linewidths=2, colors=\"darkred\")\n",
    "plt.contourf(xx, yy, Z, levels=[0, Z.max()], colors=\"palevioletred\")\n",
    "\n",
    "s = 40\n",
    "b1 = plt.scatter(X_train[:, 0], X_train[:, 1], c=\"white\", s=s, edgecolors=\"k\")\n",
    "b2 = plt.scatter(X_test[:, 0], X_test[:, 1], c=\"blueviolet\", s=s, edgecolors=\"k\")\n",
    "c = plt.scatter(X_outliers[:, 0], X_outliers[:, 1], c=\"gold\", s=s, edgecolors=\"k\")\n",
    "plt.axis(\"tight\")\n",
    "plt.xlim((-5, 5))\n",
    "plt.ylim((-5, 5))\n",
    "plt.legend(\n",
    "    [a.collections[0], b1, b2, c],\n",
    "    [\n",
    "        \"learned frontier\",\n",
    "        \"training observations\",\n",
    "        \"new regular observations\",\n",
    "        \"new abnormal observations\",\n",
    "    ],\n",
    "    loc=\"upper left\",\n",
    "    prop=matplotlib.font_manager.FontProperties(size=11),\n",
    ")\n",
    "plt.xlabel(\n",
    "    f\"errors novel regular: {n_errors_test}/40 ; errors novel abnormal: {n_errors_outliers}/40\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolation Forests\n",
    "\n",
    "Alternative to LOF is isolation forests. These forests work by randomly selecting a feature, then randomly splitting the feature between the max and min values of that feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "We're going to use the same synthetic data, so no need to generate new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Novelty Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Create the IF that uses 100 maximum samples\n",
    "\n",
    "\n",
    "# train the model\n",
    "\n",
    "\n",
    "# get the predictions for all three datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click to cheat</summary>\n",
    "\n",
    "```python\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Create the IF that uses 100 maximum samples\n",
    "isoForest = IsolationForest(max_samples=100)\n",
    "\n",
    "# train the model\n",
    "isoForest.fit(X_train)\n",
    "\n",
    "# get the predictions for all three datasets\n",
    "y_pred_train = isoForest.predict(X_train)\n",
    "y_pred_test = isoForest.predict(X_test)\n",
    "y_pred_outliers = isoForest.predict(X_outliers)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7, 7))\n",
    "# plot the line, the samples, and the nearest vectors to the plane\n",
    "xx, yy = np.meshgrid(np.linspace(-5, 5, 50), np.linspace(-5, 5, 50))\n",
    "Z = isoForest.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "plt.title(\"IsolationForest\")\n",
    "plt.contourf(xx, yy, Z, cmap=plt.cm.Blues_r)\n",
    "\n",
    "b1 = plt.scatter(X_train[:, 0], X_train[:, 1], c=\"white\", s=20, edgecolor=\"k\")\n",
    "b2 = plt.scatter(X_test[:, 0], X_test[:, 1], c=\"green\", s=20, edgecolor=\"k\")\n",
    "c = plt.scatter(X_outliers[:, 0], X_outliers[:, 1], c=\"red\", s=20, edgecolor=\"k\")\n",
    "plt.axis(\"tight\")\n",
    "plt.xlim((-5, 5))\n",
    "plt.ylim((-5, 5))\n",
    "plt.legend(\n",
    "    [b1, b2, c],\n",
    "    [\"training observations\", \"new regular observations\", \"new abnormal observations\"],\n",
    "    loc=\"upper left\",\n",
    ")\n",
    "plt.xlabel(\"$x_1$\")\n",
    "plt.ylabel(\"$x_2$\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3e8ba394dfecf69ab3b214a23e7e279956d3407d86cf3cc4fe5cfb6d1f0e6e68"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
