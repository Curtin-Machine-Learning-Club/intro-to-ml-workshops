{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction: Principal Component Analysis\n",
    "\n",
    "Sometimes, we have far too many features to work with. This is known as the *curse of dimensionality*.\n",
    "\n",
    "*Principal component analysis* is the algorithm for reducing and combining features whilst preserving information. It works by looking at the variance of each feature and constructing hyperplanes that maximises the variance.\n",
    "\n",
    "References:<br>\n",
    "Scikit learn PCA: https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html <br>\n",
    "Principal Component Analysis (PCA) with Scikit-learn: https://towardsdatascience.com/principal-component-analysis-pca-with-scikit-learn-1e84a0c731b0 <br>\n",
    "A demo of K-Means clustering on the handwritten digits data: https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_digits.html#sphx-glr-auto-examples-cluster-plot-kmeans-digits-py <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy\n",
    "%pip install matplotlib\n",
    "%pip install sklearn\n",
    "%pip install seaborn\n",
    "%pip install -U matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducing the Breast Cancer Dataset\n",
    "\n",
    "The Wisconsin breast cancer dataset has a whopping 30 features! This is a little too much for many algorithms to handle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data\n",
    "\n",
    "Let's load the data and see what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data as a Pandas DataFrame\n",
    "\n",
    "\n",
    "# Load it again as a bunch object for plotting later on\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click to cheat</summary>\n",
    "\n",
    "```python\n",
    "# Load the data as a Pandas DataFrame\n",
    "X, y = datasets.load_breast_cancer(return_X_y=True, as_frame=True)\n",
    "\n",
    "# Load it again as a bunch object for plotting later on\n",
    "cancer = datasets.load_breast_cancer()\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the first few rows of features and their names\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the first few labels\n",
    "# There are two labels: 0 for 'malignant' and 1 for 'benign'\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing our data\n",
    "\n",
    "Usually, it's best to preprocess our data to make it easier to process later on.\n",
    "\n",
    "We'll use *z*-scaling to ensure no feature's variance dominates any other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create the scaler\n",
    "\n",
    "\n",
    "# Scale the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click to cheat</summary>\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scale the data\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# create the PCA with 30 components\n",
    "# Will be using 30 so we can analyse the variance of each feature\n",
    "\n",
    "\n",
    "# fit and transform the scaled data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click to cheat</summary>\n",
    "\n",
    "```python\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# create the PCA with 30 components\n",
    "# Will be using 30 so we can analyse the variance of each feature\n",
    "pca = PCA(n_components=30)\n",
    "\n",
    "# fit and transform the scaled data\n",
    "pca.fit(X_scaled)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance preserved\n",
    "\n",
    "Now let's view the variance of the original dataset that was preserved from component to component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance of each feature\n",
    "pca.explained_variance_ratio_ * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's plot the accumulated variance\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_ * 100))\n",
    "plt.xlabel(\"Number of components\")\n",
    "plt.ylabel(\"Explained variance (%)\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, with only 6 components we have 95% of the variance!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the first few components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new PCA with only three components\n",
    "\n",
    "\n",
    "# fit the data using the scaled data\n",
    "\n",
    "\n",
    "# transform the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click to cheat</summary>\n",
    "\n",
    "```python\n",
    "# create a new PCA with only three components\n",
    "pca = PCA(n_components=3)\n",
    "\n",
    "# fit the data using the scaled data\n",
    "pca.fit(X_scaled)\n",
    "# transform the data\n",
    "X_pca = pca.transform(X_scaled)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the PCA data\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "var = np.cumsum(pca.explained_variance_ratio_ * 100)[-1]\n",
    "ax.scatter3D(X_pca[y == 0, 0], X_pca[y == 0, 1], X_pca[y == 0, 2], s=50, alpha=0.7, color='m')\n",
    "ax.scatter3D(X_pca[y == 1, 0], X_pca[y == 1, 1], X_pca[y == 1, 2], s=50, alpha=0.7, color='b')\n",
    "plt.title(f\"3D Scatterplot: {var:.2f}% variance captured\")\n",
    "plt.xlabel(\"1st principal component\")\n",
    "plt.ylabel(\"2nd principal component\")\n",
    "ax.set_zlabel(\"3rd principal component\")\n",
    "ax.legend([\"Malignant\", \"Benign\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplifying the Digits Dataset for Clustering\n",
    "\n",
    "The digits dataset has a whopping 64 features! One for each pixel.\n",
    "\n",
    "This is a lot of features to work with, so we'll reduce it first, then cluster it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data as a bunch object\n",
    "data, labels = datasets.load_digits(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an PCA with 2 components\n",
    "\n",
    "\n",
    "# Fit and transform the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click to cheat</summary>\n",
    "\n",
    "```python\n",
    "# Create an PCA with 2 components\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "# Fit and transform the data\n",
    "data_pca = pca.fit_transform(data)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Clusterer\n",
    "\n",
    "The data forms spherical clusters, so K-Means works just fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a K-means clusterer with k = 10 (one for each digit)\n",
    "\n",
    "\n",
    "# fit the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click to cheat</summary>\n",
    "\n",
    "```python\n",
    "# Create a K-means clusterer with k = 10 (one for each digit)\n",
    "kmeans = KMeans(n_clusters=10)\n",
    "\n",
    "# fit the data\n",
    "kmeans.fit(data_pca)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step size of the mesh. Decrease to increase the quality of the VQ.\n",
    "h = 0.02  # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "x_min, x_max = data_pca[:, 0].min() - 1, data_pca[:, 0].max() + 1\n",
    "y_min, y_max = data_pca[:, 1].min() - 1, data_pca[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "# Obtain labels for each point in mesh. Use last trained model.\n",
    "Z = kmeans.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(1)\n",
    "plt.clf()\n",
    "plt.imshow(\n",
    "    Z,\n",
    "    interpolation=\"nearest\",\n",
    "    extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
    "    cmap=plt.cm.Paired,\n",
    "    aspect=\"auto\",\n",
    "    origin=\"lower\",\n",
    ")\n",
    "\n",
    "plt.plot(data_pca[:, 0], data_pca[:, 1], \"k.\", markersize=2)\n",
    "# Plot the centroids as a white X\n",
    "centroids = kmeans.cluster_centers_\n",
    "plt.scatter(\n",
    "    centroids[:, 0],\n",
    "    centroids[:, 1],\n",
    "    marker=\"x\",\n",
    "    s=169,\n",
    "    linewidths=3,\n",
    "    color=\"w\",\n",
    "    zorder=10,\n",
    ")\n",
    "plt.title(\n",
    "    \"K-means clustering on the digits dataset (PCA-reduced data)\\n\"\n",
    "    \"Centroids are marked with white cross\"\n",
    ")\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.xlabel(\"1st Component\")\n",
    "plt.ylabel(\"2nd Component\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3e8ba394dfecf69ab3b214a23e7e279956d3407d86cf3cc4fe5cfb6d1f0e6e68"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
